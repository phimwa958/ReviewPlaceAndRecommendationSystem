# บทที่ 2 แนวคิด ทฤษฎี เอกสารและงานวิจัยที่เกี่ยวข้อง

เอกสารบทนี้มีวัตถุประสงค์เพื่อรวบรวมและอธิบายถึงแนวคิด ทฤษฎีพื้นฐาน และภาพรวมของงานวิจัยที่เกี่ยวข้องกับเทคโนโลยีระบบแนะนำ (Recommendation System) ซึ่งเป็นรากฐานสำคัญในการออกแบบและพัฒนาระบบแนะนำสถานที่สำหรับโปรเจกต์นี้

## 2.1 แนวคิดและทฤษฎีที่เกี่ยวข้อง

ในส่วนนี้จะอธิบายถึงทฤษฎีและเทคนิควิธีการต่างๆ ที่ถูกนำมาประยุกต์ใช้ในระบบแนะนำของโปรเจกต์ ตั้งแต่เทคนิคพื้นฐานไปจนถึงการผสมผสานในรูปแบบไฮบริด

### 2.1.1 การกรองตามความนิยม (Popularity-Based Filtering)

**หลักการพื้นฐาน**

การกรองตามความนิยมเป็นหนึ่งในรูปแบบของระบบแนะนำที่เรียบง่ายที่สุดและไม่ซับซ้อน (Non-personalized) โดยมีหลักการคือการแนะนำไอเท็มที่ได้รับความนิยมหรือเป็นที่สนใจมากที่สุดในหมู่ผู้ใช้โดยรวม (Sen, 2021) เทคนิคนี้ไม่ได้วิเคราะห์รสนิยมส่วนบุคคลของผู้ใช้แต่ละราย แต่จะใช้ข้อมูลภาพรวม เช่น จำนวนครั้งที่ไอเท็มถูกดู, ถูกซื้อ, หรือได้รับการรีวิวที่ดี เพื่อจัดอันดับและนำเสนอไอเท็มเหล่านั้นให้กับผู้ใช้ทุกคนเหมือนกัน

จุดเด่นของแนวทางนี้คือความง่ายในการนำไปใช้และประสิทธิภาพในการแก้ปัญหา "Cold Start" สำหรับผู้ใช้ใหม่ที่ระบบยังไม่มีข้อมูลพฤติกรรมเพียงพอที่จะสร้างคำแนะนำส่วนบุคคลได้ (Srikala, 2022)

**การประยุกต์ใช้ในระบบ**

ในโปรเจกต์นี้ โมเดลตามความนิยมถูกใช้เป็นหนึ่งในสามองค์ประกอบหลักของระบบแนะนำแบบไฮบริด และถูกออกแบบมาเพื่อทำหน้าที่เป็น Baseline ที่สำคัญ โดยมีการคำนวณ "คะแนนความนิยม" (Popularity Score) ที่ซับซ้อนกว่าการนับจำนวนครั้งเพียงอย่างเดียว ดังนี้:

1.  **รวบรวมเมตริก:** ระบบจะดึงข้อมูล 5 อย่างจากสถานที่แต่ละแห่ง ได้แก่
    *   คะแนนรีวิวเฉลี่ย (`average_rating`)
    *   จำนวนรีวิวทั้งหมด (`total_reviews`)
    *   จำนวนการเข้าชม (`visit_count`)
    *   จำนวนการกดไลค์ (`likes_count`)
    *   จำนวนการแชร์ (`shares_count`)
2.  **การปรับมาตราส่วน (Normalization):** เพื่อให้แต่ละเมตริกมีผลต่อคะแนนโดยรวมอย่างยุติธรรมและป้องกันไม่ให้เมตริกที่มีค่าสูงโดยธรรมชาติ (เช่น `visit_count`) มีอิทธิพลมากเกินไป ระบบจะใช้ `MinMaxScaler` ของไลบรารี Scikit-learn เพื่อปรับค่าของทุกเมตริกให้อยู่ในช่วง 0 ถึง 1
3.  **การคำนวณคะแนนถ่วงน้ำหนัก:** ระบบนำเมตริกที่ปรับค่าแล้วมาคำนวณเป็นคะแนนสุดท้ายโดยใช้ค่าน้ำหนักที่กำหนดไว้ล่วงหน้า (เช่น เรตติ้ง 30%, ไลค์ 20%, แชร์ 20%, รีวิว 20%, การเข้าชม 10%) เพื่อให้สามารถปรับจูนความสำคัญของแต่ละปัจจัยได้

ด้วยกระบวนการนี้ ระบบสามารถนำเสนอ "สถานที่ยอดนิยม" ในหน้าแรกให้กับผู้ใช้ใหม่ หรือใช้เป็นตัวเลือกสำรอง (Fallback) ในกรณีที่โมเดลอื่นที่ซับซ้อนกว่าไม่สามารถสร้างคำแนะนำได้

---
**อ้างอิง:**
*   Sen, S. (2021). *Recommender Systems*. Medium. Available at: https://medium.com/the-owl/recommender-systems-f62ad843f70c
*   Srikala, K. (2022). *Popularity Based Recommendation System*. ResearchGate. Available at: https://www.researchgate.net/publication/355773477_Popularity_Based_Recommendation_System

### 2.1.2 การกรองตามเนื้อหา (Content-Based Filtering)

**หลักการพื้นฐาน**

การกรองตามเนื้อหาเป็นเทคนิคการแนะนำที่ใช้คุณลักษณะ (Features/Attributes) ของไอเท็มเป็นหลักในการสร้างคำแนะนำ (Google, n.d.) หลักการสำคัญคือ "หากผู้ใช้ชอบไอเท็มชิ้นหนึ่งในอดีต ระบบจะแนะนำไอเท็มอื่นที่มีคุณลักษณะคล้ายคลึงกัน" ตัวอย่างเช่น หากผู้ใช้เคยให้คะแนนภาพยนตร์แนว Sci-Fi ที่มีนักแสดง A สูง ระบบก็จะแนะนำภาพยนตร์แนว Sci-Fi เรื่องอื่น หรือภาพยนตร์เรื่องอื่นที่มีนักแสดง A ร่วมแสดง

เทคนิคนี้อาศัยการสร้าง "โปรไฟล์" ที่ชัดเจนสำหรับทั้งไอเท็มและผู้ใช้ โดยโปรไฟล์ของไอเท็มคือชุดของคุณลักษณะที่อธิบายไอเท็มนั้นๆ ส่วนโปรไฟล์ของผู้ใช้คือการสรุปรวมคุณลักษณะของไอเท็มที่ผู้ใช้เคยแสดงความสนใจ จากนั้นระบบจะทำการจับคู่ระหว่างโปรไฟล์ผู้ใช้กับโปรไฟล์ไอเท็มอื่นๆ เพื่อค้นหาไอเท็มที่คล้ายคลึงที่สุด

**การประยุกต์ใช้ในระบบ**

ระบบนี้ได้นำเทคนิค Content-Based Filtering มาใช้อย่างเต็มรูปแบบและซับซ้อนเพื่อสร้างคำแนะนำ "สถานที่ที่คล้ายกัน" (Similar Places) และเป็นส่วนหนึ่งของโมเดลไฮบริด โดยมีกระบวนการดังนี้:

1.  **การสร้างโปรไฟล์สถานที่ (Item Profile Creation):** ระบบสร้างเวกเตอร์คุณลักษณะ (Feature Vector) ที่เป็นตัวแทนของสถานที่แต่ละแห่ง โดยผสมผสานข้อมูลจาก 3 แหล่งหลัก:
    *   **คุณลักษณะจากข้อความ (Text Features):** นำข้อมูลคำอธิบายสถานที่ (`description`) ซึ่งเป็นภาษาไทยมาผ่านกระบวนการประมวลผลภาษาธรรมชาติ (NLP) โดยใช้ `PyThaiNLP` ในการตัดคำ และใช้โมเดล `Word2Vec` ที่เรียนรู้ไว้แล้วเพื่อแปลงชุดของคำให้กลายเป็น Document Vector ขนาด 300 มิติ ซึ่งสามารถจับความหมายเชิงลึก (Semantic Meaning) ของเนื้อหาได้
    *   **คุณลักษณะจากหมวดหมู่ (Categorical Features):** ใช้เทคนิค `OneHotEncoder` เพื่อแปลงข้อมูลเชิงหมวดหมู่ เช่น ประเภทของสถานที่ (`category`), ที่ตั้ง (`location`), และช่วงราคา (`price_range`) ให้เป็นเวกเตอร์ที่เครื่องสามารถเข้าใจได้
    *   **คุณลักษณะเชิงตัวเลขและประชากรศาสตร์ (Numerical & Demographic Features):** นำข้อมูลตัวเลขโดยตรง เช่น คะแนนรีวิวเฉลี่ย (`average_rating`) และข้อมูลเชิงประชากรศาสตร์ของผู้ใช้ที่เคยมีปฏิสัมพันธ์กับสถานที่นั้นๆ (เช่น ค่าเฉลี่ยอายุ, การกระจายตัวของเพศ) มาเป็นส่วนหนึ่งของโปรไฟล์ด้วย

2.  **การสร้างโปรไฟล์ผู้ใช้และการคำนวณความคล้ายคลึง:**
    *   **โปรไฟล์ผู้ใช้ (User Profile):** โปรไฟล์ของผู้ใช้ถูกสร้างขึ้นจากการนำโปรไฟล์ของสถานที่ทั้งหมดที่ผู้ใช้เคยมีปฏิสัมพันธ์ด้วยมาหา "ค่าเฉลี่ยถ่วงน้ำหนัก" ซึ่งน้ำหนักจะมาจากระดับความสนใจที่ผู้ใช้มีต่อสถานที่นั้นๆ (เช่น คะแนนรีวิวที่ให้)
    *   **การคำนวณความคล้ายคลึง (Similarity Calculation):** หลังจากได้โปรไฟล์ของผู้ใช้และโปรไฟล์ของสถานที่ทั้งหมดแล้ว ระบบจะใช้ `Cosine Similarity` ซึ่งเป็นฟังก์ชันทางคณิตศาสตร์ที่ใช้วัดความคล้ายคลึงระหว่างเวกเตอร์สองเวกเตอร์ เพื่อคำนวณหาคะแนนความเหมือนกันระหว่างโปรไฟล์ของผู้ใช้กับโปรไฟล์ของสถานที่ทุกแห่ง สถานที่ที่มีคะแนนความคล้ายคลึงสูงสุดจะถูกนำมาแนะนำ

วิธีการนี้ทำให้ระบบสามารถแนะนำสถานที่ที่ตรงกับรสนิยมเฉพาะตัวของผู้ใช้ได้ดี และยังสามารถแนะนำสถานที่ที่ไม่เป็นที่นิยม (Niche) ได้ ตราบใดที่สถานที่นั้นมีคุณลักษณะคล้ายกับสิ่งที่ผู้ใช้เคยชอบ

---
**อ้างอิง:**
*   Google. (n.d.). *Content-based filtering | Machine Learning*. Google for Developers. Available at: https://developers.google.com/machine-learning/recommendation/content-based/basics

### 2.1.3 การกรองแบบร่วมมือ (Collaborative Filtering)

**หลักการพื้นฐาน**

การกรองแบบร่วมมือเป็นวิธีการสร้างคำทำนาย (Filtering) เกี่ยวกับความสนใจของผู้ใช้โดยอัตโนมัติ โดยอาศัยข้อมูลความชอบที่รวบรวมมาจากผู้ใช้จำนวนมาก (Collaborating) (Wikipedia, 2023) แนวทางนี้ไม่ได้อาศัยคุณลักษณะของไอเท็ม แต่จะวิเคราะห์จากพฤติกรรมของผู้ใช้โดยตรง สมมติฐานหลักคือ "หากบุคคล A และบุคคล B มีความเห็นต่อเรื่องหนึ่งคล้ายกัน พวกเขามีแนวโน้มที่จะเห็นด้วยในเรื่องอื่นๆ มากกว่าคนแปลกหน้า"

ภายในแนวทางนี้ เทคนิคที่ได้รับความนิยมคือ **User-Based Collaborative Filtering (UBCF)** ซึ่งทำงานโดยการค้นหากลุ่มผู้ใช้ที่มีรสนิยมคล้ายกับผู้ใช้เป้าหมาย (เรียกว่า "เพื่อนบ้าน" หรือ Neighbors) จากนั้นจึงแนะนำไอเท็มที่เพื่อนบ้านเหล่านั้นชื่นชอบแต่ผู้ใช้เป้าหมายยังไม่เคยมีปฏิสัมพันธ์ด้วย (IBM, n.d.)

**การประยุกต์ใช้ในระบบ**

โปรเจกต์นี้ใช้เทคนิค User-Based Collaborative Filtering เป็นหนึ่งในโมเดลหลักสำหรับสร้างคำแนะนำส่วนบุคคล (Personalized Recommendations) โดยมีขั้นตอนการดำเนินงานที่ชัดเจนและออกแบบมาเพื่อประสิทธิภาพ ดังนี้:

1.  **การสร้างเมทริกซ์ปฏิสัมพันธ์ระหว่างผู้ใช้และสถานที่ (User-Item Interaction Matrix):**
    *   ขั้นตอนแรกคือการรวบรวมพฤติกรรมทั้งหมดของผู้ใช้มาสร้างเป็น "คะแนนปฏิสัมพันธ์" (Interaction Score) ที่สะท้อนความสนใจของผู้ใช้ต่อสถานที่นั้นๆ โดยไม่ได้ใช้แค่คะแนนรีวิว แต่เป็นการถ่วงน้ำหนักจากหลายกิจกรรม:
        *   **การรีวิว (Review):** คะแนนรีวิวที่ผู้ใช้ให้ (ถูกทำให้เป็นมาตรฐาน)
        *   **การกดไลค์ (Like):** ได้รับค่าน้ำหนักคงที่ (เช่น 0.6)
        *   **การเข้าชม (View):** ได้รับค่าน้ำหนักคงที่ (เช่น 0.3)
        *   **การแชร์ (Share):** ได้รับค่าน้ำหนักคงที่ (เช่น 0.7)
    *   คะแนนเหล่านี้จะถูกนำมาสร้างเป็นเมทริกซ์ขนาดใหญ่ที่มีผู้ใช้เป็นแถวและสถานที่ต่างๆ เป็นคอลัมน์

2.  **การคำนวณความคล้ายคลึงของผู้ใช้ (User Similarity Calculation):**
    *   **การปรับค่ากลาง (Mean-Centering):** เพื่อลดอคติที่เกิดจากพฤติกรรมการให้คะแนนที่ต่างกันของแต่ละคน (เช่น ผู้ใช้บางคนมีแนวโน้มให้คะแนนสูงกว่าปกติ) ระบบจะทำการปรับค่าในเมทริกซ์โดยการลบค่าเฉลี่ยของคะแนนทั้งหมดที่ผู้ใช้คนนั้นเคยให้ ซึ่งจะทำให้การเปรียบเทียบระหว่างผู้ใช้มีความแม่นยำมากขึ้น
    *   **การใช้ Cosine Similarity:** หลังจากปรับค่าในเมทริกซ์แล้ว ระบบจะใช้ `Cosine Similarity` เพื่อคำนวณหาคะแนนความคล้ายคลึงระหว่างเวกเตอร์ของผู้ใช้แต่ละคู่ ผลลัพธ์ที่ได้คือ User-Similarity Matrix ที่บอกว่าผู้ใช้แต่ละคนมีความคล้ายคลึงกับผู้ใช้อื่นๆ มากน้อยเพียงใด

3.  **การสร้างคำแนะนำ (Recommendation Generation):**
    *   เมื่อต้องการสร้างคำแนะนำให้ผู้ใช้เป้าหมาย ระบบจะไปค้นหาผู้ใช้กลุ่มเล็กๆ ที่มีคะแนนความคล้ายคลึงสูงสุด (Top-K Neighbors) จากเมทริกซ์ความคล้ายคลึง
    *   จากนั้น ระบบจะทำนายคะแนนที่ผู้ใช้เป้าหมายน่าจะให้กับสถานที่ที่ตนยังไม่เคยมีปฏิสัมพันธ์ด้วย โดยคำนวณจากค่าเฉลี่ยถ่วงน้ำหนักของคะแนนที่ "เพื่อนบ้าน" เหล่านั้นได้ให้กับสถานที่นั้นๆ สถานที่ที่ได้คะแนนทำนายสูงสุดจะถูกนำมาเป็นคำแนะนำ

วิธีการนี้มีประสิทธิภาพสูงในการค้นพบไอเท็มใหม่ๆ ที่ผู้ใช้อาจสนใจ (Serendipity) โดยอาศัยภูมิปัญญาจากกลุ่มคน (Wisdom of the Crowd)

---
**อ้างอิง:**
*   Wikipedia. (2023). *Collaborative filtering*. Available at: https://en.wikipedia.org/wiki/Collaborative_filtering
*   IBM. (n.d.). *What is collaborative filtering?*. IBM. Available at: https://www.ibm.com/think/topics/collaborative-filtering

### 2.1.4 ระบบแนะนำแบบไฮบริด (Hybrid Recommendation Systems)

**หลักการพื้นฐาน**

ระบบแนะนำแบบไฮบริดคือระบบที่ผสมผสานเทคนิคการแนะนำตั้งแต่สองวิธีขึ้นไปเพื่อพยายามรวมจุดแข็งและลดจุดอ่อนของแต่ละวิธี (Burke, 2002) ตัวอย่างเช่น การกรองแบบร่วมมือ (Collaborative Filtering) อาจประสบปัญหา "Cold Start" เมื่อเจอผู้ใช้ใหม่ที่ยังไม่มีข้อมูลพฤติกรรม แต่ปัญหานี้สามารถบรรเทาได้โดยการใช้เทคนิคการกรองตามเนื้อหา (Content-Based Filtering) เข้ามาช่วยในระยะแรก การผสมผสานนี้ทำให้ระบบมีความแม่นยำและความยืดหยุ่นสูงกว่าการใช้เทคนิคใดเทคนิคหนึ่งเพียงอย่างเดียว

การออกแบบระบบไฮบริดสามารถทำได้หลายรูปแบบ เช่น การสลับระหว่างเทคนิค, การแสดงผลจากหลายเทคนิคพร้อมกัน, หรือการนำคุณลักษณะจากเทคนิคหนึ่งไปเป็นข้อมูลป้อนเข้าให้อีกเทคนิคหนึ่ง แต่หนึ่งในแนวทางที่ทรงพลังคือ **การถ่วงน้ำหนัก (Weighted Hybrid)** ซึ่งเป็นการรวม "คะแนน" ที่ได้จากระบบแนะนำย่อยๆ เข้าด้วยกันโดยให้น้ำหนักความสำคัญที่แตกต่างกันไป

**การประยุกต์ใช้ในระบบ**

โปรเจกต์นี้เลือกใช้สถาปัตยกรรมแบบ **Weighted Hybrid** ที่มีความซับซ้อนและชาญฉลาด โดยเป็นการผสานผลลัพธ์จากโมเดลทั้ง 3 ประเภทที่กล่าวมาข้างต้น (Popularity-Based, Content-Based, และ User-Based) เพื่อสร้างคำแนะนำสุดท้ายที่มีความแม่นยำและเหมาะสมกับบริบทของผู้ใช้แต่ละคนมากที่สุด

หัวใจสำคัญของสถาปัตยกรรมนี้คือ **การถ่วงน้ำหนักแบบไดนามิก (Dynamic Weighting)** ซึ่งหมายความว่าสัดส่วนอิทธิพลของแต่ละโมเดลจะ "ไม่คงที่" แต่จะ "ปรับเปลี่ยนไปตามพฤติกรรมของผู้ใช้" โดยมีตรรกะดังนี้:

*   **สำหรับผู้ใช้ใหม่ (มีกิจกรรมน้อยกว่า 5 ครั้ง):**
    *   **น้ำหนัก:** `(User-Based: 0.1, Content-Based: 0.3, Popularity: 0.6)`
    *   **เหตุผล:** ระบบจะให้น้ำหนักกับ **Popularity-Based** มากที่สุด เพื่อแนะนำสถานที่ที่เป็นที่นิยมโดยรวม และใช้ **Content-Based** เป็นส่วนเสริมหากผู้ใช้เริ่มมีกิจกรรมบ้าง เนื่องจากข้อมูลสำหรับ User-Based ยังไม่น่าเชื่อถือ

*   **สำหรับผู้ใช้ระยะกลาง (มีกิจกรรม 5-30 ครั้ง):**
    *   **น้ำหนัก:** `(User-Based: 0.4, Content-Based: 0.5, Popularity: 0.1)`
    *   **เหตุผล:** เมื่อผู้ใช้มีข้อมูลพฤติกรรมมากขึ้น น้ำหนักของ **User-Based** และ **Content-Based** จะเพิ่มขึ้นอย่างมีนัยสำคัญ และลดความสำคัญของ Popularity-Based ลง

*   **สำหรับผู้ใช้ที่ใช้งานเป็นประจำ (มีกิจกรรมมากกว่า 30 ครั้ง):**
    *   **น้ำหนัก:** `(User-Based: 0.6, Content-Based: 0.4, Popularity: 0.0)`
    *   **เหตุผล:** ระบบจะเชื่อมั่นในข้อมูลพฤติกรรมของผู้ใช้และผู้ใช้คนอื่นๆ มากที่สุด โดยให้น้ำหนักกับ **User-Based** สูงที่สุด และตัด Popularity-Based ออกไปโดยสิ้นเชิง เพื่อมอบคำแนะนำที่เป็นส่วนตัว (Personalized) อย่างแท้จริง

กระบวนการรวมคะแนนจะเริ่มจากการแปลง "อันดับ" ที่ได้จากแต่ละโมเดลให้เป็น "คะแนน" ด้วยฟังก์ชัน **Exponential Decay** (เพื่อให้สถานะที่อยู่อันดับต้นๆ มีคะแนนสูงกว่าอันดับท้ายๆ อย่างชัดเจน) จากนั้นจึงนำคะแนนมาปรับมาตรฐาน (Normalize) และรวมกันตามสัดส่วนน้ำหนักไดนามิกข้างต้น ผลลัพธ์คือรายการแนะนำที่ปรับเปลี่ยนได้อย่างยืดหยุ่นและเหมาะสมกับผู้ใช้ในทุกช่วงของการใช้งาน

---
**อ้างอิง:**
*   Burke, R. (2002). *Hybrid Recommender Systems: Survey and Experiments*. User Modeling and User-Adapted Interaction, 12(4), 331-370.

### 2.1.5 การประมวลผลภาษาธรรมชาติ (Natural Language Processing - NLP)

**หลักการพื้นฐาน**

การประมวลผลภาษาธรรมชาติ หรือ NLP (Natural Language Processing) เป็นสาขาหนึ่งของปัญญาประดิษฐ์ (AI) ที่มุ่งเน้นการทำให้คอมพิวเตอร์สามารถเข้าใจ ตีความ และสร้างภาษามนุษย์ได้ (ทั้งในรูปแบบข้อความและเสียง) ในบริบทของระบบแนะนำ NLP มีบทบาทสำคัญอย่างยิ่งในการสกัดข้อมูลเชิงลึกจากข้อมูลที่ไม่มีโครงสร้าง (Unstructured Data) เช่น คำอธิบายสินค้า, บทวิจารณ์, หรือเนื้อหาบทความ

หนึ่งในเทคนิคที่ทรงพลังที่สุดใน NLP สมัยใหม่คือ **การฝังคำ (Word Embedding)** ซึ่งเป็นวิธีการแทนคำศัพท์ด้วยเวกเตอร์ของตัวเลข (Vectors) โมเดลที่ได้รับความนิยมอย่างสูงคือ **Word2Vec** (Mikolov et al., 2013) ซึ่งจะเรียนรู้การแทนค่าคำศัพท์โดยอาศัยบริบทของคำนั้นๆ ผลลัพธ์คือคำที่มีความหมายใกล้เคียงกันจะมีเวกเตอร์ที่อยู่ใกล้กันในปริภูมิเวกเตอร์ (Vector Space) ทำให้สามารถคำนวณความคล้ายคลึงทางความหมายได้ ซึ่งก้าวข้ามข้อจำกัดของการจับคู่ด้วยคีย์เวิร์ดแบบดั้งเดิม

**การประยุกต์ใช้ในระบบ**

เนื่องจากข้อมูลสำคัญส่วนหนึ่งของโปรเจกต์นี้คือ "คำอธิบายสถานที่" (`description`) ซึ่งเป็นข้อความภาษาไทย ระบบจึงจำเป็นต้องใช้ NLP เพื่อแปลงข้อมูลส่วนนี้ให้เป็นคุณลักษณะ (Feature) ที่โมเดล Content-Based สามารถนำไปใช้ประโยชน์ได้ โดยมีขั้นตอนดังนี้:

1.  **การประมวลผลภาษาไทยด้วย `PyThaiNLP`:**
    *   ภาษาไทยมีความท้าทายเฉพาะตัวคือการเขียนประโยคยาวติดต่อกันโดยไม่มีการเว้นวรรคระหว่างคำ ทำให้การแบ่งคำ (Tokenization) เป็นขั้นตอนที่สำคัญและจำเป็นอย่างยิ่ง
    *   ระบบได้เลือกใช้ **`PyThaiNLP`** ซึ่งเป็นไลบรารีมาตรฐานสำหรับประมวลผลภาษาไทย (PyThaiNLP Team, n.d.) เพื่อจัดการกับข้อความภาษาไทย โดยใช้ฟังก์ชัน `word_tokenize` (ด้วยเอนจิน `newmm`) ในการตัดสายอักขระให้กลายเป็นรายการของคำศัพท์ที่ถูกต้องแม่นยำ รวมถึงการทำความสะอาดข้อความ เช่น การลบสัญลักษณ์ที่ไม่จำเป็นและการทำให้เป็นตัวพิมพ์เล็ก (Normalization)

2.  **การสร้างเวกเตอร์ด้วย `Word2Vec`:**
    *   หลังจากได้รายการคำศัพท์ (Tokens) จากขั้นตอนที่แล้ว ระบบจะนำคำศัพท์แต่ละคำไปแปลงให้เป็นเวกเตอร์ตัวเลขโดยใช้โมเดล `Word2Vec` ที่ผ่านการฝึกฝนกับคลังข้อมูลภาษาไทยขนาดใหญ่มาแล้ว (โหลดผ่าน `pythainlp.word_vector`)
    *   เพื่อให้ได้เวกเตอร์ที่เป็นตัวแทนของ "คำอธิบายสถานที่ทั้งหมด" (Document Vector) ระบบจะใช้วิธีการหาค่าเฉลี่ยของเวกเตอร์ของทุกๆ คำที่อยู่ในคำอธิบายนั้น
    *   เวกเตอร์ผลลัพธ์ขนาด 300 มิตินี้ จะกลายเป็น "คุณลักษณะจากข้อความ" (Text Features) ที่มีความหมายเชิงลึกและถูกนำไปรวมกับคุณลักษณะอื่นๆ (เช่น ประเภท, ที่ตั้ง, ราคา) เพื่อสร้างเป็นโปรไฟล์ที่สมบูรณ์ของสถานที่แต่ละแห่งในโมเดล Content-Based Filtering

ด้วยกระบวนการนี้ ระบบจึงสามารถเข้าใจได้ว่า "คาเฟ่ริมน้ำ" มีความหมายใกล้เคียงกับ "ร้านกาแฟติดแม่น้ำ" แม้จะใช้คำศัพท์คนละชุดกันก็ตาม ซึ่งช่วยเพิ่มคุณภาพของคำแนะนำให้สูงขึ้นอย่างมีนัยสำคัญ

---
**อ้างอิง:**
*   Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). *Efficient Estimation of Word Representations in Vector Space*. arXiv preprint arXiv:1301.3781.
*   PyThaiNLP Team. (n.d.). *PyThaiNLP/pythainlp: Thai natural language processing in Python*. GitHub. Available at: https://github.com/PyThaiNLP/pythainlp

### 2.1.6 ปัญหาการเริ่มต้น (The Cold Start Problem)

**นิยามของปัญหา**

ปัญหาการเริ่มต้น หรือ Cold Start เป็นหนึ่งในความท้าทายที่สำคัญและเป็นที่รู้จักกันดีที่สุดสำหรับระบบแนะนำ (Recommender Systems) ปัญหานี้เกิดขึ้นในสถานการณ์ที่ระบบยังไม่มีข้อมูลสะสมเพียงพอเกี่ยวกับ "ผู้ใช้" หรือ "ไอเท็ม" ทำให้ไม่สามารถสร้างคำแนะนำที่แม่นยำและน่าเชื่อถือได้ (Wikipedia, n.d.) โดยทั่วไป ปัญหา Cold Start สามารถแบ่งออกได้เป็น 2 กรณีหลัก:

1.  **ปัญหาสำหรับผู้ใช้ใหม่ (User Cold Start):** เกิดขึ้นเมื่อมีผู้ใช้ใหม่เข้ามาในระบบเป็นครั้งแรก ผู้ใช้รายนี้ยังไม่มีประวัติการใช้งาน, การให้คะแนน, หรือกิจกรรมใดๆ ทำให้ระบบที่อาศัยข้อมูลพฤติกรรมในอดีต เช่น Collaborative Filtering ไม่สามารถทำงานได้ เนื่องจากไม่รู้ว่าผู้ใช้คนนี้มีความชอบหรือรสนิยมแบบใด และไม่สามารถหา "เพื่อนบ้าน" ที่คล้ายกันได้
2.  **ปัญหาสำหรับไอเท็มใหม่ (Item Cold Start):** เกิดขึ้นเมื่อมีไอเท็มใหม่ถูกเพิ่มเข้ามาในระบบ เช่น สถานที่ท่องเที่ยวแห่งใหม่, ร้านอาหารที่เพิ่งเปิด, หรือสินค้าชิ้นใหม่ ไอเท็มนี้จะยังไม่มีใครเคยให้คะแนนหรือมีปฏิสัมพันธ์ด้วย ทำให้โมเดลที่ต้องอาศัยข้อมูลจากผู้ใช้ (เช่น Popularity-Based และ Collaborative Filtering) ไม่สามารถนำไอเท็มนี้ไปแนะนำได้ เพราะยังไม่มีข้อมูลบ่งชี้ว่าไอเท็มนี้ดีหรือไม่ดี หรือใครน่าจะชอบมัน

**แนวทางการแก้ไขในระบบ**

สถาปัตยกรรมแบบไฮบริดของโปรเจกต์นี้ถูกออกแบบมาโดยคำนึงถึงการรับมือกับปัญหา Cold Start ทั้งสองรูปแบบอย่างเป็นระบบ ซึ่งเป็นหนึ่งในเหตุผลหลักที่ต้องมีการผสมผสานหลายโมเดลเข้าด้วยกัน:

*   **การแก้ไขปัญหา User Cold Start:**
    *   เมื่อมีผู้ใช้ใหม่ลงทะเบียนเข้ามาในระบบ และยังไม่มีข้อมูลกิจกรรมเพียงพอ (ตามเกณฑ์คือมีกิจกรรมน้อยกว่า 5 ครั้ง) ระบบจะใช้กลยุทธ์ **Dynamic Weighting** ในโมเดลไฮบริดเพื่อให้น้ำหนักกับ **Popularity-Based Model (60%)** และ **Content-Based Model (30%)** เป็นหลัก
    *   ซึ่งหมายความว่าผู้ใช้ใหม่จะได้รับคำแนะนำที่เป็น "สถานที่ยอดนิยม" ซึ่งเป็นทางเลือกที่ปลอดภัยและมีแนวโน้มที่จะมีคุณภาพดี และเมื่อผู้ใช้เริ่มมีปฏิสัมพันธ์กับสถานที่บางแห่ง ระบบก็จะเริ่มใช้ข้อมูลคุณลักษณะของสถานที่นั้นๆ มาแนะนำสถานที่ที่ "คล้ายกัน" ผ่าน Content-Based Model ได้ทันที

*   **การแก้ไขปัญหา Item Cold Start:**
    *   เมื่อมีการเพิ่มสถานที่ใหม่เข้ามาในระบบ สถานที่นั้นจะมีข้อมูลคุณลักษณะ (Content) ครบถ้วนทันที เช่น คำอธิบาย, ประเภท, ที่ตั้ง, และช่วงราคา
    *   **Content-Based Model** สามารถทำงานได้ทันทีโดยไม่จำเป็นต้องรอให้มีผู้ใช้มาให้คะแนนหรือเข้าชมก่อน มันสามารถวิเคราะห์โปรไฟล์ของสถานที่ใหม่นี้ และนำไปจับคู่กับโปรไฟล์ของผู้ใช้ที่มีรสนิยมตรงกันเพื่อสร้างคำแนะนำได้เลย
    *   ด้วยเหตุนี้ สถานที่ใหม่ๆ จึงมีโอกาสถูกค้นพบโดยผู้ใช้ที่น่าจะสนใจมันจริงๆ ตั้งแต่วันแรก ซึ่งช่วยแก้ปัญหาการที่ไอเท็มใหม่ "จมหาย" ไปจากระบบได้อย่างมีประสิทธิภาพ

โดยสรุป การออกแบบระบบให้เป็นแบบไฮบริดไม่เพียงแต่ช่วยเพิ่มความแม่นยำโดยรวม แต่ยังเป็นกลยุทธ์สำคัญที่ทำให้ระบบมีความแข็งแกร่ง (Robust) สามารถให้บริการแก่ผู้ใช้และจัดการกับไอเท็มได้ในทุกสถานการณ์ ตั้งแต่เริ่มต้นจนมีข้อมูลสะสมเป็นจำนวนมาก

---
**อ้างอิง:**
*   Wikipedia. (n.d.). *Cold start (recommender systems)*. Wikipedia. Available at: https://en.wikipedia.org/wiki/Cold_start_(recommender_systems)

## 2.2 งานวิจัยหรือระบบงานที่เกี่ยวข้อง

ในส่วนนี้จะทำการสำรวจและสรุปงานวิจัยที่เกี่ยวข้องกับระบบแนะนำสำหรับการท่องเที่ยว ซึ่งมีแนวทางและเป้าหมายที่คล้ายคลึงกับโปรเจกต์นี้ เพื่อแสดงให้เห็นถึงภาพรวมของเทคนิคที่ใช้ในแวดวงวิชาการและเปรียบเทียบกับแนวทางที่ใช้ในการพัฒนาระบบนี้

**1. งานวิจัย: A Novel Hybrid Recommender System for the Tourism Domain (Gavalas et al., 2023)**

*   **แนวทางและวัตถุประสงค์:**
    งานวิจัยนี้นำเสนอระบบแนะนำสถานที่ท่องเที่ยว (Points of Interest - POIs) แบบไฮบริดสำหรับแอปพลิเคชันบนมือถือ โดยมีเป้าหมายเพื่อสร้างคำแนะนำส่วนบุคคลให้กับนักท่องเที่ยว ระบบไฮบริดของพวกเขาเป็นการผสมผสานระหว่าง (a) **Bayesian Preferences Elicitation** ซึ่งเป็นกลไกที่ให้ผู้ใช้ประเมินรูปภาพทั่วๆ ไป (เช่น ภาพชายหาด, ภาพพิพิธภัณฑ์) เพื่อสร้างโปรไฟล์ความชอบของผู้ใช้ในเบื้องต้น และ (b) **Content-Based Filtering** ที่ใช้ความคล้ายคลึงกันของคุณลักษณะสถานที่เพื่อสร้างคำแนะนำ

*   **ผลลัพธ์:**
    ผลการทดลองชี้ให้เห็นว่าโมเดลแบบไฮบริดให้ประสิทธิภาพในด้านความแม่นยำ (Precision) ของคำแนะนำสูงกว่าการใช้โมเดล Content-Based เพียงอย่างเดียว และยังสามารถหาจุดสมดุลระหว่างการสอบถามข้อมูลจากผู้ใช้ (เพื่อไม่ให้ผู้ใช้รู้สึกรำคาญ) กับคุณภาพของคำแนะนำได้

*   **การเปรียบเทียบกับโปรเจกต์นี้:**
    *   **ความคล้ายคลึง:** ทั้งสองระบบเป็นแบบไฮบริดและมุ่งเน้นด้านการท่องเที่ยวเหมือนกัน
    *   **ความแตกต่าง:** โปรเจกต์นี้ใช้การผสมผสานระหว่าง Popularity, Content-Based, และ Collaborative Filtering โดยอาศัยข้อมูลพฤติกรรมผู้ใช้โดยปริยาย (Implicit Feedback) ในขณะที่งานวิจัยนี้ใช้แนวทางไฮบริดที่แตกต่างออกไป คือการผสม Content-Based เข้ากับการสอบถามความชอบจากผู้ใช้โดยตรง (Explicit Feedback) ในช่วงเริ่มต้น ซึ่งเป็นคนละวิธีในการแก้ปัญหา User Cold Start

**2. งานวิจัย: A Hybrid Recommender Model based on Information Retrieval for Mexican Tourism (Carranza-Alarcon et al., 2022)**

*   **แนวทางและวัตถุประสงค์:**
    งานวิจัยนี้ถูกนำเสนอในการแข่งขัน Rest-Mex 2022 โดยมีเป้าหมายเพื่อทำนายระดับความพึงพอใจ (1 ถึง 5 ดาว) ที่นักท่องเที่ยวคนหนึ่งจะมีต่อสถานที่ท่องเที่ยวในเม็กซิโก พวกเขาสร้างโมเดลแบบไฮบริดที่ใช้เทคนิคจาก **Information Retrieval (IR)** และ **Natural Language Processing (NLP)** โดยวิเคราะห์ข้อมูลจากรีวิวใน TripAdvisor

*   **ผลลัพธ์:**
    ทีมวิจัยสามารถสร้างโมเดลที่ทำนายคะแนนความพึงพอใจได้ ซึ่งเป็นส่วนสำคัญในการสร้างระบบแนะนำที่มีประสิทธิภาพ โดยแสดงให้เห็นถึงศักยภาพของการใช้เทคนิค NLP ในการทำความเข้าใจข้อความรีวิวเพื่อจับคู่ผู้ใช้กับสถานที่

*   **การเปรียบเทียบกับโปรเจกต์นี้:**
    *   **ความคล้ายคลึง:** ทั้งสองระบบใช้ NLP เพื่อวิเคราะห์ข้อมูลที่เป็นข้อความ (Text) ในบริบทของการท่องเที่ยว และใช้ข้อมูลจากรีวิวเป็นแหล่งข้อมูลสำคัญ
    *   **ความแตกต่าง:** เป้าหมายหลักของงานวิจัยนี้คือการ "ทำนายคะแนน" (Rating Prediction) ซึ่งเป็นส่วนหนึ่งของระบบแนะนำ ในขณะที่เป้าหมายของโปรเจกต์นี้คือการ "สร้างรายการแนะนำ" (Item Ranking) โดยตรง นอกจากนี้ โปรเจกต์นี้ใช้ Word2Vec ซึ่งเป็นเทคนิคการทำ Embedding ที่สามารถจับความหมายเชิงลึกของคำได้ดี ในขณะที่งานวิจัยจำนวนมากในลักษณะนี้อาจยังใช้เทคนิคแบบดั้งเดิม เช่น TF-IDF

จากงานวิจัยข้างต้น จะเห็นได้ว่าแนวทางการใช้ระบบแบบไฮบริดและการประยุกต์ใช้ NLP เป็นแนวทางที่ทันสมัยและได้รับการยอมรับอย่างกว้างขวางในการพัฒนาระบบแนะนำสำหรับการท่องเที่ยว ซึ่งสอดคล้องกับแนวทางการออกแบบและพัฒนาของโปรเจกต์นี้ ที่มีการผสมผสานเทคนิคที่หลากหลายเพื่อสร้างระบบที่แข็งแกร่งและแม่นยำ

---
**อ้างอิง:**
*   Gavalas, D., et al. (2023). *A Novel Hybrid Recommender System for the Tourism Domain*. MDPI. Available at: https://www.mdpi.com/1999-4893/16/4/215
*   Carranza-Alarcon, G., et al. (2022). *A Hybrid Recommender Model based on Information Retrieval for Mexican Tourism Text in Rest-Mex 2022*. CEUR-WS.org. Available at: https://ceur-ws.org/Vol-3202/restmex-paper2.pdf

## 2.3 เทคโนโลยีและเครื่องมือที่ใช้ (Technologies and Tools Used)

นอกเหนือจากแนวคิดและทฤษฎีทางวิชาการแล้ว การพัฒนาระบบนี้ยังอาศัยเทคโนโลยี, เฟรมเวิร์ก, และไลบรารี Open Source ที่ทันสมัยจำนวนมาก ซึ่งเครื่องมือแต่ละชนิดมีบทบาทหน้าที่แตกต่างกันไปในการสร้างส่วนประกอบต่างๆ ของโปรเจกต์ ดังนี้

### 2.3.1 สถาปัตยกรรมหลักและส่วนหลังบ้าน (Core Architecture & Backend)

*   **Django:** เป็น Web Framework ภาษา Python ที่ใช้เป็นแกนหลักของแอปพลิเคชันทั้งหมด ทำหน้าที่จัดการสถาปัตยกรรมแบบ Model-View-Template (MVT), จัดการ URL (Routing), ระบบจัดการผู้ใช้ (User Authentication), และเป็นส่วนที่เชื่อมต่อกับฐานข้อมูลผ่าน ORM (Object-Relational Mapping)
*   **Gunicorn:** เป็น Web Server Gateway Interface (WSGI) สำหรับ Python ที่ใช้ในการ Deploy แอปพลิเคชัน Django เพื่อให้สามารถรองรับการใช้งานจริง (Production) ได้อย่างมีประสิทธิภาพและเสถียรภาพ

### 2.3.2 ส่วนหน้าบ้าน (Frontend)

*   **HTML/CSS/JavaScript:** เป็นเทคโนโลยีพื้นฐานในการสร้างโครงสร้าง, จัดรูปแบบ, และเพิ่มความสามารถในการโต้ตอบกับผู้ใช้ให้กับหน้าเว็บ
*   **Bootstrap / Tailwind CSS:** เป็น CSS Framework ที่ถูกนำมาใช้ร่วมกันเพื่อเร่งความเร็วในการพัฒนาหน้าตาของเว็บไซต์ให้สวยงามและรองรับการแสดงผลบนอุปกรณ์หลายขนาด (Responsive Design)
*   **Chart.js:** เป็นไลบรารี JavaScript ที่ใช้สำหรับสร้างกราฟและแผนภูมิต่างๆ เพื่อแสดงผลข้อมูลเชิงวิเคราะห์ในหน้าแดชบอร์ดของผู้ดูแลระบบ

### 2.3.3 ฐานข้อมูลและการจัดการข้อมูล (Database & Data Management)

*   **MySQL:** เป็นระบบจัดการฐานข้อมูลเชิงสัมพันธ์ (Relational Database Management System - RDBMS) ที่ใช้เป็นที่จัดเก็บข้อมูลหลักของระบบทั้งหมด เช่น ข้อมูลผู้ใช้, สถานที่, รีวิว, และกิจกรรมต่างๆ
*   **Redis:** เป็นระบบฐานข้อมูลแบบ In-memory ที่มีความเร็วสูง ถูกใช้ใน 2 บทบาทหลัก คือ (1) **Message Broker** สำหรับ Celery เพื่อเป็นตัวกลางในการรับส่ง Task และ (2) **Caching Layer** เพื่อเก็บข้อมูลที่ประมวลผลแล้วหรือข้อมูลที่ถูกเรียกใช้บ่อยๆ (เช่น ผลลัพธ์จากระบบแนะนำ, ข้อมูลโปรไฟล์) เพื่อลดภาระของฐานข้อมูลและเพิ่มความเร็วในการตอบสนองของระบบ

### 2.3.4 การประมวลผลแบบเบื้องหลัง (Asynchronous Processing)

*   **Celery:** เป็น Distributed Task Queue ที่สำคัญอย่างยิ่งสำหรับระบบแนะนำ ใช้ในการสั่งรัน Task ที่ใช้เวลาประมวลผลนาน (เช่น การคำนวณ User-Similarity Matrix, การสร้าง Hybrid Recommendations) ในเบื้องหลัง (Background Process) โดยไม่ขัดขวางการทำงานของหน้าเว็บหลัก ทำให้ผู้ใช้ได้รับประสบการณ์ที่ดี

### 2.3.5 วิทยาศาสตร์ข้อมูลและการประมวลผลภาษาธรรมชาติ (Data Science & NLP)

*   **Pandas:** เป็นไลบรารีหลักสำหรับการจัดการและวิเคราะห์ข้อมูลในรูปแบบตาราง (Dataframe) ใช้ในการโหลด, ทำความสะอาด, และแปลงข้อมูล (Data Wrangling) ที่ดึงมาจากฐานข้อมูลเพื่อเตรียมพร้อมสำหรับการนำไปใช้ในโมเดลระบบแนะนำ
*   **NumPy:** เป็นไลบรารีพื้นฐานสำหรับการคำนวณทางคณิตศาสตร์และวิทยาศาสตร์ใน Python โดยเฉพาะการทำงานกับ Array หลายมิติ (Multi-dimensional Array) ซึ่งถูกใช้โดยไลบรารีอื่นๆ เช่น Pandas และ Scikit-learn
*   **Scikit-learn:** เป็นไลบรารี Machine Learning ที่ครอบคลุมและใช้งานง่าย ในโปรเจกต์นี้ถูกใช้สำหรับเครื่องมือต่างๆ เช่น `MinMaxScaler` และ `StandardScaler` ในการปรับมาตราส่วนข้อมูล และ `cosine_similarity` ในการคำนวณหาความคล้ายคลึง
*   **Gensim:** เป็นไลบรารีที่เชี่ยวชาญด้าน Topic Modeling และ Vector Space Modeling ในโปรเจกต์นี้ถูกใช้เพื่อสร้างและจัดการโมเดล `Word2Vec` สำหรับแปลงข้อความคำอธิบายสถานที่ให้เป็นเวกเตอร์
*   **PyThaiNLP:** เป็นไลบรารีสำหรับประมวลผลภาษาไทยโดยเฉพาะ มีบทบาทสำคัญในการ "ตัดคำ" (Word Tokenization) จากประโยคภาษาไทย เพื่อเตรียมข้อมูลให้ Gensim สามารถนำไปประมวลผลต่อได้

### 2.3.6 การจัดการสภาพแวดล้อม (Containerization & DevOps)

*   **Docker / Docker Compose:** เป็นเทคโนโลยี Containerization ที่ใช้ในการจำลองสภาพแวดล้อมของโปรเจกต์ทั้งหมด (เว็บแอปพลิเคชัน, ฐานข้อมูล, Redis, Celery) ให้อยู่ในรูปแบบของ Container ที่แยกจากกัน ทำให้ง่ายต่อการติดตั้ง, พัฒนา, และ Deploy ระบบในสภาพแวดล้อมที่แตกต่างกันโดยไม่มีปัญหาเรื่องความเข้ากันไม่ได้ของเวอร์ชัน
